{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1l9PdpeanaiSO26ZF5HnGYj6GrNaaeyQ3",
      "authorship_tag": "ABX9TyPTaqoGVH6C+ONBCaucwH1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSaillok/ArxesGlwsswn/blob/main/porject_info_retrieval_1064886.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set elasticsearch and tensorflow\n",
        "\n",
        "Εισαγωγή των απαραίτητων βιβλιοθηκών για το project και αρχικοποίηση του elasticsearch."
      ],
      "metadata": {
        "id": "gQ5jVa8J6V5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io\n",
        "!pip3 install elasticsearch==6.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61XJxXnK44gn",
        "outputId": "5b8104aa-a63f-4849-91df-b5cf7dbccb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.28.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.28.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-io) (0.28.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.28.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting elasticsearch==6.0.0\n",
            "  Downloading elasticsearch-6.0.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 10.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.23,>=1.21.1\n",
            "  Downloading urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 38.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, elasticsearch\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed elasticsearch-6.0.0 urllib3-1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "hl4SP_Nl5GjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e003c5e-d234-49a0-e5ee-d0d9532bf7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2gC-ytc5Nn4",
        "outputId": "890dfa98-169c-4665-df6e-ac891f896b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow-io version: 0.28.0\n",
            "tensorflow version: 2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n",
        "tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "sudo chown -R daemon:daemon elasticsearch-7.9.2/\n",
        "shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zGuHROv5WZu",
        "outputId": "60b19e0f-dd3b-4b07-8cac-7551a2d65e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "metadata": {
        "id": "hPCogTQU5sDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sleep for few seconds to let the instance start.\n",
        "time.sleep(20)"
      ],
      "metadata": {
        "id": "--JfwBNE5tD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "ps -ef | grep elasticsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2PBhpnJ550x",
        "outputId": "1471c8c2-e7cd-44c5-89c2-12d644068a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root         335     333  0 00:00 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch\n",
            "daemon       336     335 99 00:00 ?        00:00:23 /content/elasticsearch-7.9.2/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-15119995131702870432 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/content/elasticsearch-7.9.2 -Des.path.conf=/content/elasticsearch-7.9.2/config -Des.distribution.flavor=oss -Des.distribution.type=tar -Des.bundled_jdk=true -cp /content/elasticsearch-7.9.2/lib/* org.elasticsearch.bootstrap.Elasticsearch\n",
            "root         572     570  0 00:00 ?        00:00:00 grep elasticsearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STJw3FWSCvYE",
        "outputId": "7504b509-6b38-4c3d-f8a4-d79ee834e637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"467b97bfceac\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"v2qTHZn2TROlLUUNCZPJyA\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"oss\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n"
      ],
      "metadata": {
        "id": "cjPy9Oxr7p9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge τα 3 csv αρχεία"
      ],
      "metadata": {
        "id": "e7hUfNlfaBua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "os.chdir(\"/content/drive/MyDrive\")\n",
        "\n",
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
        "\n",
        "#combine all files in the list\n",
        "merged = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "merged.to_csv( \"merged.csv\", index=False, encoding='utf8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEKsgtvhiQsJ",
        "outputId": "c7f40e3b-9042-47e4-cf2b-3e76208f87d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e27c01416e3c>:10: DtypeWarning: Columns (1,3,5,6,8,9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  merged = pd.concat([pd.read_csv(f) for f in all_filenames ])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Upl.csv αρχείου στο elasticsearch."
      ],
      "metadata": {
        "id": "7j0cxFlIaDvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "ES_NODES = \"http://localhost:9200\"\n",
        "\n",
        "es = Elasticsearch(hosts = [ES_NODES])\n",
        "\n",
        "with open(\"/content/drive/MyDrive/BX-Books.csv\", encoding=\"utf8\") as f:\n",
        "\treader = csv.DictReader(f)\n",
        "\thelpers.bulk(es, reader, index='bx-books')\n",
        "\n",
        "with open(\"/content/drive/MyDrive/BX-Users.csv\", encoding=\"utf8\") as f1:\n",
        "\treader = csv.DictReader(f1)\n",
        "\thelpers.bulk(es, reader, index='bx-users')\n",
        "\n",
        "with open(\"/content/drive/MyDrive/BX-Book-Ratings.csv\", encoding=\"utf8\") as f2:\n",
        "\treader = csv.DictReader(f2)\n",
        "\thelpers.bulk(es, reader, index='bx-book-ratings')\n",
        "\n",
        "print(\"Upload Completed\")"
      ],
      "metadata": {
        "id": "HjjedKJ4Fypo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39344c26-4e5c-48d1-a44a-3fa838e928d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/_cat/indices\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CBElEkewAMz",
        "outputId": "0f1a8d6b-7273-4103-9391-3f08844cb4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yellow open bx-books        JaAPWczmQ5OlMFbpNJnPKQ 1 1  18765 0   16mb   16mb\n",
            "yellow open bx-book-ratings CB47iXqBQsaUZyrip6RhUg 1 1 248500 0 11.2mb 11.2mb\n",
            "yellow open bx-users        IRpbtmQ-Tjyta32RbN-u4A 1 1 130373 0 11.5mb 11.5mb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/bx-users/_search\" -sH 'Content-Type: application/json' -sd'{  \"size\": 2,  \"query\": {    \"match_all\": {}  }}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpYhgx6yIk_",
        "outputId": "12b5089f-7680-4611-e849-500f4320c329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"took\":101,\"timed_out\":false,\"_shards\":{\"total\":1,\"successful\":1,\"skipped\":0,\"failed\":0},\"hits\":{\"total\":{\"value\":10000,\"relation\":\"gte\"},\"max_score\":1.0,\"hits\":[{\"_index\":\"bx-users\",\"_type\":\"_doc\",\"_id\":\"biBW-YQBx5R9hzMic2_T\",\"_score\":1.0,\"_source\":{\"uid\": \"1\", \"location\": \"nyc, new york, usa\", \"age\": \"\"}},{\"_index\":\"bx-users\",\"_type\":\"_doc\",\"_id\":\"byBW-YQBx5R9hzMic2_T\",\"_score\":1.0,\"_source\":{\"uid\": \"2\", \"location\": \"stockton, california, usa\", \"age\": \"18.0\"}}]}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Αναζήτηση βάση αλφαριθμητικό string"
      ],
      "metadata": {
        "id": "N21ddfbbUjxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.helpers import scan\n",
        "import pandas as pd\n",
        "\n",
        "ES_NODES = \"http://localhost:9200\"\n",
        "\n",
        "es = Elasticsearch(hosts = [ES_NODES])\n",
        "\n",
        "#alphanumeric + integer\n",
        "userId = input(\"Give the user ID: \\n\")\n",
        "\n",
        "#alpanumeric input\n",
        "keyword = input(\"Give a string: \\n\")\n",
        "\n",
        "def getBook():\n",
        "\n",
        "  # Elasticsearch Query.\n",
        "\tquery = {\n",
        "\t\t\"query\": {\n",
        "\t\t\t\"match\": {\n",
        "\t\t\t\t\"book_title\": {\n",
        "\t\t\t\t\t\"query\": keyword,\n",
        "\t\t\t\t\t\"operator\": \"and\"\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}#,\n",
        "    #\"aggs\": {\n",
        "      #\"book_count\" : {\n",
        "          #\"value_count\" : { \n",
        "              #\"field\" : \"type\" \n",
        "              #} \n",
        "            #}\n",
        "          #}\n",
        "  }\n",
        "\n",
        "  # Collecting all the data using Scan function.\n",
        "\trel = scan(\n",
        "\t\tclient=es,\n",
        "\t\tquery=query,\n",
        "\t\tscroll='1m',\n",
        "\t\tindex='bx-books',\n",
        "\t\traise_on_error=True,\n",
        "\t\tpreserve_order=False,\n",
        "\t\tclear_scroll=True\n",
        "\t)\n",
        " \n",
        " \t# This list keeps the response.\n",
        "\tresult = list(rel)\n",
        "\ttemp = []\n",
        "\n",
        "  # Clear the response data from metadata like _id, _type, _index.\n",
        "\tfor hit in result:\n",
        "\t\t# So, we're getting only '_source'\n",
        "\t\ttemp.append(hit['_source'])\n",
        "\n",
        "\t# Create a dataframe\n",
        "\tbooks_df = pd.DataFrame(temp)\n",
        "\n",
        "\treturn books_df\n",
        "\n",
        "\n",
        "\n",
        "def getRatings():\n",
        "  # Elasticsearch Query.\n",
        "\tquery = {\n",
        "\t\t\"query\": {\n",
        "\t\t\t\"match\": {\n",
        "\t\t\t\t\"uid\": {\n",
        "\t\t\t\t\t\"query\": userId\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "  # Collecting all the data using Scan function.\n",
        "\trel1 = scan(\n",
        "\t\tclient=es,\n",
        "\t\tquery=query,\n",
        "\t\tscroll='1m',\n",
        "\t\tindex='bx-book-ratings',\n",
        "\t\traise_on_error=True,\n",
        "\t\tpreserve_order=False,\n",
        "\t\tclear_scroll=True\n",
        "\t)\n",
        " \n",
        " \t# This list keeps the response.\n",
        "\tresult = list(rel1)\n",
        "\ttemp1 = []\n",
        "\n",
        "  # Clear the response data from metadata like _id, _type, _index.\n",
        "\tfor hit in result:\n",
        "\t\t# So, we're getting only '_source'\n",
        "\t\ttemp1.append(hit['_source'])\n",
        "\n",
        "\t# Create a dataframe\n",
        "\tuser_df = pd.DataFrame(temp1)\n",
        "\n",
        "\treturn user_df\n",
        "\n",
        "# Calling the function\n",
        "df = getBook()\n",
        "df1 = getRatings()\n",
        "\n",
        "# Sorting the Dataframe\n",
        "sorted_df = df.sort_values([\"book_title\"], ascending=False)\n",
        "\n",
        "\n",
        "print(sorted_df)\n",
        "print('\\n\\n')\n",
        "print(df1)\n",
        "print('\\n')\n",
        "\n",
        "mergedPd = pd.merge(sorted_df, df1)\n",
        "print(mergedPd)\n",
        "print('\\n\\n')"
      ],
      "metadata": {
        "id": "MyXsNsHvTk0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ae3386-9c07-4450-8dc6-33c917dea6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the user ID: \n",
            "8\n",
            "Give a string: \n",
            "Canada\n",
            "         isbn                                         book_title  \\\n",
            "1  0771095066  Poets of Contemporary Canada (New Canadian Lib...   \n",
            "2  0968067824                                   Crazy For Canada   \n",
            "3  0919891276  Book of Alternative Services of the Anglican C...   \n",
            "0  1553373405                                      ABC of Canada   \n",
            "\n",
            "            book_author year_of_publication                 publisher  \\\n",
            "1            Eli Mandel                1972      New Canadian Library   \n",
            "2          Noa Schwartz                1997          Tumbleweed Press   \n",
            "3  Not Applicable (Na )                1988  Continuum Intl Pub Group   \n",
            "0     Kim Bellefontaine                2002            Kids Can Press   \n",
            "\n",
            "                                             summary                category  \n",
            "1  This important anthology affirms the continuat...              ['poetry']  \n",
            "2  Lester B. Beaver describes his vacation in Can...    ['juvenile fiction']  \n",
            "3  The pew edition of the prayer book of the Angl...  ['anglican communion']  \n",
            "0  From Arctic to Zamboni, kids can follow the al...    ['juvenile fiction']  \n",
            "\n",
            "\n",
            "\n",
            "   uid        isbn rating\n",
            "0    8  0002005018      5\n",
            "1    8  0060973129      0\n",
            "2    8  0374157065      0\n",
            "3    8  0393045218      0\n",
            "4    8  0399135782      0\n",
            "5    8  0425176428      0\n",
            "6    8  0671870432      0\n",
            "7    8  0679425608      0\n",
            "8    8  074322678X      5\n",
            "9    8  0771074670      0\n",
            "10   8  080652121X      0\n",
            "11   8  0887841740      5\n",
            "12   8  1552041778      5\n",
            "13   8  1558746218      0\n",
            "14   8  1567407781      6\n",
            "15   8  1575663937      6\n",
            "16   8  1881320189      7\n",
            "\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [isbn, book_title, book_author, year_of_publication, publisher, summary, category, uid, rating]\n",
            "Index: []\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}